{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import dbGeneration as db\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 126320 data points\n"
     ]
    }
   ],
   "source": [
    "tensorInputs, raw_labels = db.get_tensorinputs_and_labels()\n",
    "tensorInputs = np.asarray(tensorInputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_labels = []\n",
    "for i in raw_labels:\n",
    "    if i == -1:\n",
    "        pre_labels.append([1,0])\n",
    "    else:\n",
    "        pre_labels.append([0,1])\n",
    "\n",
    "pre_labels = np.asarray(pre_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126320, 2)\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ..., \n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_labels.shape)\n",
    "print(pre_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126320\n"
     ]
    }
   ],
   "source": [
    "print(len(tensorInputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_SAMPLES = len(tensorInputs)\n",
    "N_TRAIN = 120000\n",
    "N_VALIDATION = int((N_SAMPLES - N_TRAIN)/2)\n",
    "N_BATCHES = int(N_TRAIN/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data to avoid grouping among games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(tensorInputs)):\n",
    "    pairs.append([tensorInputs[i], pre_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.],\n",
      "       [ 9., -1., -1., -1., -1., -1., -1., -1., -1.,  9.],\n",
      "       [ 9., -1., -1., -1., -1., -1., -1., -1.,  1.,  9.],\n",
      "       [ 9., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  9.],\n",
      "       [ 9., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  9.],\n",
      "       [ 9., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  9.],\n",
      "       [ 9., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  9.],\n",
      "       [ 9.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  9.],\n",
      "       [ 9., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  9.],\n",
      "       [ 9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.]]), array([1, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(pairs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensorInputs = []\n",
    "pre_labels = []\n",
    "\n",
    "for i in pairs:\n",
    "    tensorInputs.append(i[0])\n",
    "    pre_labels.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gameboards = tensorInputs[:N_TRAIN]\n",
    "validation_gameboards = tensorInputs[N_TRAIN:N_TRAIN+N_VALIDATION]\n",
    "test_gameboards = tensorInputs[N_TRAIN+N_VALIDATION:]\n",
    "\n",
    "train_labels = pre_labels[:N_TRAIN]\n",
    "validation_labels = pre_labels[N_TRAIN:N_TRAIN+N_VALIDATION]\n",
    "test_labels = pre_labels[N_TRAIN+N_VALIDATION:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "3160\n",
      "3160\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gameboards))\n",
    "print(len(validation_gameboards))\n",
    "print(len(test_gameboards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.  9.  9.  9.  9.  9.  9.  9.  9.  9.]\n",
      " [ 9. -1. -1. -1. -1. -1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1. -1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1. -1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1. -1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1.  1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1.  1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1. -1. -1. -1. -1.  9.]\n",
      " [ 9. -1. -1. -1. -1. -1. -1. -1. -1.  9.]\n",
      " [ 9.  9.  9.  9.  9.  9.  9.  9.  9.  9.]] [1 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_gameboards[0], test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameboards = tf.placeholder(tf.float32, (None, 10, 10, 1), name=\"gameBoards\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w = tf.Variable(tf.truncated_normal([64, 2], mean=1.0, stddev=0.5), name=\"weights\")\\nb = tf.Variable(tf.zeros([1,2]), name=\"bias\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"w = tf.Variable(tf.truncated_normal([64, 2], mean=1.0, stddev=0.5), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([1,2]), name=\"bias\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# First Convulutional layer, small 2x2 filter\n",
    "conv1 = tf.layers.conv2d(gameboards, 32, 2, padding=\"same\", name=\"Conv1\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, 2, 2, name=\"Pool1\")\n",
    "\n",
    "# Increased the second convolution size to 4x4, larger frames aiming to capture larger features.\n",
    "conv2 = tf.layers.conv2d(pool1, 64, 4, padding=\"same\", name=\"Conv2\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "# Reshape the 2D tensor back to 1D to be fed into \"Dense\"\n",
    "# Flatten out the pooling - GET THIS NUMBER FROM POOL.SHAPE\n",
    "pool2_flat = tf.reshape(pool2, (-1, int(2*2*64)), name=\"Pool2_Flat\")\n",
    "\n",
    "\n",
    "# The dropout allows us to train a subset of the neurons at any given iteration.  \n",
    "keep_prob = tf.placeholder(tf.float32, name=\"Keep_Probability\")\n",
    "\n",
    "\n",
    "# A dense layer with dropout\n",
    "# DENSE - a fully connected linear transofmration of every dimension of the data\n",
    "dense = tf.layers.dense(pool2_flat, int(2*2*64), activation=tf.nn.relu, name=\"Dense\")\n",
    "\n",
    "# DROPOUT - if set to 0.5, rendomly select 50% of the neurons to ignore (different with each computation)\n",
    "dropout = tf.nn.dropout(dense, keep_prob, name=\"Dropout\")\n",
    "\n",
    "dense2 = tf.layers.dense(dropout, int(2*64), activation=tf.nn.relu, name=\"Dense2\")\n",
    "dropout2 = tf.nn.dropout(dense2, keep_prob, name=\"Dropout2\")\n",
    "\n",
    "# A dense layer to classify the final values. Only 2 neurons. \n",
    "predictions = tf.layers.dense(dropout2, 2, activation=None, name=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2), Dimension(2), Dimension(64)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add two convolution layers with max pooling\n",
    "#conv1 = tf.layers.conv1d(gameboards_1d, 32, 5, padding=\"same\", name=\"Conv1\")\n",
    "\n",
    "## 2D\n",
    "\n",
    "conv1 = tf.layers.conv2d(gameboards_2d, 64, 5, padding=\"same\", name=\"Conv1\")\n",
    "pool1 = tf.layers.max_pooling2d(conv1, 4, 4, name=\"Pool1\")\n",
    "conv2 = tf.layers.conv2d(pool1, 128, 5, padding=\"same\", name=\"Conv2\")\n",
    "pool2 = tf.layers.max_pooling2d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "# Reshape the 2D tensor back to 1D to be fed into \"Dense\"\n",
    "pool2_flat = tf.reshape(pool2, (-1, 8*8*2), name=\"Pool2_Flat\")\n",
    "'''\n",
    "\n",
    "## 1D\n",
    "conv1 = tf.layers.conv1d(gameboards_1d, 32, 5, padding=\"same\", name=\"Conv1\")\n",
    "pool1 = tf.layers.max_pooling1d(conv1, 2, 2, name=\"Pool1\")\n",
    "conv2 = tf.layers.conv1d(pool1, 200, 5, padding=\"same\", name=\"Conv2\")\n",
    "pool2 = tf.layers.max_pooling1d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "# 50 is batch size, image is 8*8 (?)\n",
    "pool2_flat = tf.reshape(pool2, (-1, 8*8*50), name=\"Pool2_Flat\")\n",
    "'''\n",
    "\n",
    "# A dense layer with dropout\n",
    "dense = tf.layers.dense(pool2_flat, 512, activation=tf.nn.relu, name=\"Dense\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"Keep_Probability\")\n",
    "dropout = tf.nn.dropout(dense, keep_prob, name=\"Dropout\")\n",
    "\n",
    "# The original dense layer to compute logits that are later used for classification\n",
    "logits = tf.layers.dense(dropout, 2, activation=None, name=\"Logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(128)]),\n",
       " TensorShape([Dimension(None), Dimension(128)]),\n",
       " TensorShape([Dimension(None), Dimension(512)]),\n",
       " TensorShape([Dimension(None), Dimension(2)]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can take a look at the shapes of some tensors\n",
    "(pool2.shape, pool2_flat.shape, dropout.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logits = tf.add(tf.matmul(gameboards, w), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(64), Dimension(2)]),\n",
       " TensorShape([Dimension(1), Dimension(2)]),\n",
       " TensorShape([Dimension(None), Dimension(2)]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape, b.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# None, as in, this is not yet defined, there could be any number of them input. \n",
    "# 2, as in, there are two elements in the one-hot vector\n",
    "\n",
    "labels = tf.placeholder(tf.int32, [None, 2], name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This loss is the elementwise loss\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "# We want the mean loss\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an error rate to evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Error\"):\n",
    "    error = tf.reduce_mean(\n",
    "        tf.cast(\n",
    "            tf.not_equal(tf.argmax(logits, axis=1), tf.argmax(labels, axis=1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Error\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "number_of_training_samples = len(list(train_gameboards))\n",
    "print(number_of_training_samples)\n",
    "\n",
    "number_of_samples_per_batch = 64\n",
    "\n",
    "number_of_batches = int(number_of_training_samples / number_of_samples_per_batch)\n",
    "print(number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "print(number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(number_of_samples_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.693146288394928, \tError: 0.484375\n",
      "Loss: 0.6975248456001282, \tError: 0.515625\n",
      "Loss: 0.690526008605957, \tError: 0.5\n",
      "Loss: 0.6898193359375, \tError: 0.46875\n",
      "Loss: 0.6749790906906128, \tError: 0.390625\n"
     ]
    }
   ],
   "source": [
    "#for epoch in range(5):\n",
    "    #randomise the data\n",
    "\n",
    "for i in range(number_of_batches):\n",
    "    first_index = i*number_of_samples_per_batch\n",
    "    second_index = (i*number_of_samples_per_batch) + number_of_samples_per_batch\n",
    "    batch = train_gameboards[first_index:second_index]\n",
    "    batchLabels = train_labels[first_index:second_index]\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        Error, Loss = sess.run([error, loss], feed_dict={gameboards:batch, labels:batchLabels, keep_prob:1.0})\n",
    "        print(\"Loss: {}, \\tError: {}\".format(Loss, Error))\n",
    "    sess.run(train, feed_dict={gameboards:batch, labels:batchLabels, keep_prob:1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Error = sess.run(error, feed_dict={gameboards:test_gameboards, labels:test_labels, keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47486\n"
     ]
    }
   ],
   "source": [
    "print(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
