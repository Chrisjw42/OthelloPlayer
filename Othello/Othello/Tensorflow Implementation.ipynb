{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import dbGeneration as db\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 15790 data points\n"
     ]
    }
   ],
   "source": [
    "tensorInputs, raw_labels = db.get_tensorinputs_and_labels()\n",
    "tensorInputs = np.asarray(tensorInputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_labels = []\n",
    "for i in raw_labels:\n",
    "    if i == -1:\n",
    "        pre_labels.append([1,0])\n",
    "    else:\n",
    "        pre_labels.append([0,1])\n",
    "\n",
    "pre_labels = np.asarray(pre_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15790, 2)\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ..., \n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_labels.shape)\n",
    "print(pre_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gameboards = tensorInputs[0:14000]\n",
    "test_gameboards = tensorInputs[14000:15790]\n",
    "train_labels = pre_labels[0:14000]\n",
    "test_labels = pre_labels[14000:15790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-order the training data, so the batches are more mixed\n",
    "data = list(zip(train_gameboards, train_labels))\n",
    "random.shuffle(data)\n",
    "train_gameboards = []\n",
    "train_labels = []\n",
    "for i in data:\n",
    "    train_gameboards.append([i[0]][0])\n",
    "    train_labels.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0. -1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] [1 0]\n",
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " -1.  1.  1.  1.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  1.\n",
      " -1. -1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_gameboards[0], test_labels[0])\n",
    "print()\n",
    "print(train_gameboards[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameboards = tf.placeholder(tf.float32, (None, 64), name=\"gameBoards\")\n",
    "gameboards_2d = tf.reshape(gameboards, (-1, 8, 8, 1), name=\"gameBoards_2D\")\n",
    "gameboards_1d = tf.reshape(gameboards, (-1, 64, 1), name=\"gameBoards_2D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.truncated_normal([64, 2], mean=1.0, stddev=0.5), name=\"weights\")\n",
    "b = tf.Variable(tf.ones([1,2]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add two convolution layers with max pooling\n",
    "#conv1 = tf.layers.conv1d(gameboards_1d, 32, 5, padding=\"same\", name=\"Conv1\")\n",
    "\n",
    "## 2D\n",
    "'''\n",
    "conv1 = tf.layers.conv2d(gameboards_2d, 64, 5, padding=\"same\", name=\"Conv1\")\n",
    "pool1 = tf.layers.max_pooling2d(conv1, 2, 2, name=\"Pool1\")\n",
    "conv2 = tf.layers.conv2d(pool1, 128, 5, padding=\"same\", name=\"Conv2\")\n",
    "pool2 = tf.layers.max_pooling2d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "# Reshape the 2D tensor back to 1D to be fed into \"Dense\"\n",
    "pool2_flat = tf.reshape(pool2, (-1, 8*8*8), name=\"Pool2_Flat\")\n",
    "'''\n",
    "\n",
    "## 1D\n",
    "conv1 = tf.layers.conv1d(gameboards_1d, 32, 5, padding=\"same\", name=\"Conv1\")\n",
    "pool1 = tf.layers.max_pooling1d(conv1, 2, 2, name=\"Pool1\")\n",
    "conv2 = tf.layers.conv1d(pool1, 200, 5, padding=\"same\", name=\"Conv2\")\n",
    "pool2 = tf.layers.max_pooling1d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "# 50 is batch size, image is 8*8 (?)\n",
    "pool2_flat = tf.reshape(pool2, (-1, 8*8*50), name=\"Pool2_Flat\")\n",
    "\n",
    "# A dense layer with dropout\n",
    "dense = tf.layers.dense(pool2_flat, 512, activation=tf.nn.relu, name=\"Dense\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"Keep_Probability\")\n",
    "dropout = tf.nn.dropout(dense, keep_prob, name=\"Dropout\")\n",
    "\n",
    "# The original dense layer to compute logits that are later used for classification\n",
    "logits = tf.layers.dense(dropout, 2, activation=None, name=\"Logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(16), Dimension(200)]),\n",
       " TensorShape([Dimension(None), Dimension(3200)]),\n",
       " TensorShape([Dimension(None), Dimension(512)]),\n",
       " TensorShape([Dimension(None), Dimension(2)]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can take a look at the shapes of some tensors\n",
    "(pool2.shape, pool2_flat.shape, dropout.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logits = tf.add(tf.matmul(gameboards, w), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(64), Dimension(2)]),\n",
       " TensorShape([Dimension(1), Dimension(2)]),\n",
       " TensorShape([Dimension(None), Dimension(2)]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape, b.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# None, as in, this is not yet defined, there could be any number of them input. \n",
    "# 2, as in, there are two elements in the one-hot vector\n",
    "\n",
    "labels = tf.placeholder(tf.int32, [None, 2], name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This loss is the elementwise loss\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "# We want the mean loss\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an error rate to evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Error\"):\n",
    "    error = tf.reduce_mean(\n",
    "        tf.cast(\n",
    "            tf.not_equal(tf.argmax(logits, axis=1), tf.argmax(labels, axis=1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Error\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "437\n"
     ]
    }
   ],
   "source": [
    "number_of_training_samples = len(list(train_gameboards))\n",
    "print(number_of_training_samples)\n",
    "\n",
    "number_of_samples_per_batch = 32\n",
    "\n",
    "number_of_batches = int(number_of_training_samples / number_of_samples_per_batch)\n",
    "print(number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    }
   ],
   "source": [
    "print(number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(number_of_samples_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18114687502384186, \tError: 0.125\n",
      "Loss: 0.03276273235678673, \tError: 0.0\n",
      "Loss: 0.18298836052417755, \tError: 0.125\n",
      "Loss: 0.10911297798156738, \tError: 0.0625\n",
      "Loss: 0.13843530416488647, \tError: 0.09375\n",
      "Loss: 0.11138470470905304, \tError: 0.09375\n",
      "Loss: 0.13289068639278412, \tError: 0.09375\n",
      "Loss: 0.27651116251945496, \tError: 0.1875\n",
      "Loss: 0.05733189731836319, \tError: 0.03125\n",
      "Loss: 0.17461490631103516, \tError: 0.09375\n",
      "Loss: 0.08577390015125275, \tError: 0.03125\n",
      "Loss: 0.06169934570789337, \tError: 0.03125\n",
      "Loss: 0.13560457527637482, \tError: 0.09375\n",
      "Loss: 0.08085232973098755, \tError: 0.03125\n",
      "Loss: 0.1334208995103836, \tError: 0.09375\n",
      "Loss: 0.19343867897987366, \tError: 0.125\n",
      "Loss: 0.09272146970033646, \tError: 0.0625\n",
      "Loss: 0.1548590511083603, \tError: 0.15625\n",
      "Loss: 0.11252652853727341, \tError: 0.09375\n",
      "Loss: 0.12777607142925262, \tError: 0.03125\n",
      "Loss: 0.1766306310892105, \tError: 0.0625\n",
      "Loss: 0.16358394920825958, \tError: 0.125\n",
      "Loss: 0.19927041232585907, \tError: 0.09375\n",
      "Loss: 0.1349705159664154, \tError: 0.0625\n",
      "Loss: 0.1605570763349533, \tError: 0.03125\n",
      "Loss: 0.08231906592845917, \tError: 0.03125\n",
      "Loss: 0.08561162650585175, \tError: 0.0625\n",
      "Loss: 0.13624030351638794, \tError: 0.09375\n",
      "Loss: 0.18372471630573273, \tError: 0.1875\n",
      "Loss: 0.036954689770936966, \tError: 0.03125\n",
      "Loss: 0.02368113584816456, \tError: 0.0\n",
      "Loss: 0.12086805701255798, \tError: 0.09375\n",
      "Loss: 0.16089698672294617, \tError: 0.125\n",
      "Loss: 0.07174880057573318, \tError: 0.03125\n",
      "Loss: 0.13960716128349304, \tError: 0.15625\n",
      "Loss: 0.03294819965958595, \tError: 0.0\n",
      "Loss: 0.05619291961193085, \tError: 0.03125\n",
      "Loss: 0.06767198443412781, \tError: 0.03125\n",
      "Loss: 0.06836255639791489, \tError: 0.0625\n",
      "Loss: 0.13507917523384094, \tError: 0.09375\n",
      "Loss: 0.12279105186462402, \tError: 0.09375\n",
      "Loss: 0.16994625329971313, \tError: 0.125\n",
      "Loss: 0.15296714007854462, \tError: 0.09375\n",
      "Loss: 0.09320006519556046, \tError: 0.0625\n",
      "Loss: 0.1474822461605072, \tError: 0.15625\n",
      "Loss: 0.032460056245326996, \tError: 0.0\n",
      "Loss: 0.184663325548172, \tError: 0.09375\n",
      "Loss: 0.10851024836301804, \tError: 0.0625\n",
      "Loss: 0.13306555151939392, \tError: 0.125\n",
      "Loss: 0.10043267905712128, \tError: 0.09375\n",
      "Loss: 0.10359247028827667, \tError: 0.03125\n",
      "Loss: 0.3083876371383667, \tError: 0.25\n",
      "Loss: 0.05313441529870033, \tError: 0.0625\n",
      "Loss: 0.18637073040008545, \tError: 0.09375\n",
      "Loss: 0.08244205266237259, \tError: 0.03125\n",
      "Loss: 0.06332974880933762, \tError: 0.03125\n",
      "Loss: 0.15262667834758759, \tError: 0.09375\n",
      "Loss: 0.08798801153898239, \tError: 0.03125\n",
      "Loss: 0.1811700463294983, \tError: 0.125\n",
      "Loss: 0.19539859890937805, \tError: 0.125\n",
      "Loss: 0.10709859430789948, \tError: 0.03125\n",
      "Loss: 0.14333760738372803, \tError: 0.09375\n",
      "Loss: 0.11597428470849991, \tError: 0.09375\n",
      "Loss: 0.14228524267673492, \tError: 0.0625\n",
      "Loss: 0.1758655309677124, \tError: 0.0625\n",
      "Loss: 0.16949515044689178, \tError: 0.125\n",
      "Loss: 0.19720321893692017, \tError: 0.125\n",
      "Loss: 0.1292303204536438, \tError: 0.0625\n",
      "Loss: 0.07402034848928452, \tError: 0.03125\n",
      "Loss: 0.07554532587528229, \tError: 0.03125\n",
      "Loss: 0.09262581169605255, \tError: 0.0625\n",
      "Loss: 0.12832647562026978, \tError: 0.09375\n",
      "Loss: 0.18050433695316315, \tError: 0.15625\n",
      "Loss: 0.21428798139095306, \tError: 0.0625\n",
      "Loss: 0.01830548793077469, \tError: 0.0\n",
      "Loss: 0.13079777359962463, \tError: 0.0625\n",
      "Loss: 0.16122756898403168, \tError: 0.125\n",
      "Loss: 0.11152654141187668, \tError: 0.03125\n",
      "Loss: 0.1408570408821106, \tError: 0.09375\n",
      "Loss: 0.04638209193944931, \tError: 0.03125\n",
      "Loss: 0.06756243854761124, \tError: 0.03125\n",
      "Loss: 0.0697864443063736, \tError: 0.03125\n",
      "Loss: 0.07196567207574844, \tError: 0.0625\n",
      "Loss: 0.11087413132190704, \tError: 0.09375\n",
      "Loss: 0.22579804062843323, \tError: 0.09375\n",
      "Loss: 0.3942524492740631, \tError: 0.15625\n",
      "Loss: 0.13149459660053253, \tError: 0.0625\n",
      "Loss: 0.07910653948783875, \tError: 0.03125\n",
      "Loss: 0.24852561950683594, \tError: 0.15625\n",
      "Loss: 0.0571160688996315, \tError: 0.0\n",
      "Loss: 0.46034252643585205, \tError: 0.15625\n",
      "Loss: 0.10570753365755081, \tError: 0.0625\n",
      "Loss: 0.23905742168426514, \tError: 0.09375\n",
      "Loss: 0.15610750019550323, \tError: 0.125\n",
      "Loss: 0.1623571217060089, \tError: 0.125\n",
      "Loss: 0.2803403437137604, \tError: 0.15625\n",
      "Loss: 0.07008084654808044, \tError: 0.03125\n",
      "Loss: 0.39783233404159546, \tError: 0.09375\n",
      "Loss: 0.09175186604261398, \tError: 0.0625\n",
      "Loss: 0.0710899755358696, \tError: 0.03125\n",
      "Loss: 0.12270193547010422, \tError: 0.0625\n",
      "Loss: 0.08107932657003403, \tError: 0.0625\n",
      "Loss: 0.11846886575222015, \tError: 0.09375\n",
      "Loss: 0.22358417510986328, \tError: 0.15625\n",
      "Loss: 0.14535486698150635, \tError: 0.0625\n",
      "Loss: 0.15671056509017944, \tError: 0.0625\n",
      "Loss: 0.10887765884399414, \tError: 0.03125\n",
      "Loss: 0.15483656525611877, \tError: 0.09375\n",
      "Loss: 0.19525501132011414, \tError: 0.15625\n",
      "Loss: 0.13742348551750183, \tError: 0.15625\n",
      "Loss: 0.22110506892204285, \tError: 0.09375\n",
      "Loss: 0.12915483117103577, \tError: 0.03125\n",
      "Loss: 0.08598744124174118, \tError: 0.03125\n",
      "Loss: 0.07811443507671356, \tError: 0.0\n",
      "Loss: 0.08136618137359619, \tError: 0.0625\n",
      "Loss: 0.12840723991394043, \tError: 0.09375\n",
      "Loss: 0.22284172475337982, \tError: 0.125\n",
      "Loss: 0.044807810336351395, \tError: 0.03125\n",
      "Loss: 0.027359552681446075, \tError: 0.0\n",
      "Loss: 0.1162523627281189, \tError: 0.09375\n",
      "Loss: 0.1433282196521759, \tError: 0.09375\n",
      "Loss: 0.06129658967256546, \tError: 0.0\n",
      "Loss: 0.1520671248435974, \tError: 0.125\n",
      "Loss: 0.06231473386287689, \tError: 0.03125\n",
      "Loss: 0.07829006016254425, \tError: 0.03125\n",
      "Loss: 0.0703132301568985, \tError: 0.0\n",
      "Loss: 0.08605299890041351, \tError: 0.0625\n",
      "Loss: 0.16736944019794464, \tError: 0.09375\n",
      "Loss: 0.2742166221141815, \tError: 0.125\n",
      "Loss: 0.1467151641845703, \tError: 0.09375\n",
      "Loss: 0.12205589562654495, \tError: 0.09375\n",
      "Loss: 0.4440678060054779, \tError: 0.0625\n",
      "Loss: 0.18472084403038025, \tError: 0.125\n",
      "Loss: 0.06752622127532959, \tError: 0.03125\n",
      "Loss: 0.25490114092826843, \tError: 0.09375\n",
      "Loss: 0.10480828583240509, \tError: 0.0625\n",
      "Loss: 0.16019965708255768, \tError: 0.125\n",
      "Loss: 0.0901397317647934, \tError: 0.09375\n",
      "Loss: 0.14420244097709656, \tError: 0.09375\n",
      "Loss: 0.21590545773506165, \tError: 0.15625\n",
      "Loss: 0.061474937945604324, \tError: 0.03125\n",
      "Loss: 0.2861725687980652, \tError: 0.1875\n",
      "Loss: 0.1401873677968979, \tError: 0.0625\n",
      "Loss: 0.07799561321735382, \tError: 0.03125\n",
      "Loss: 0.13827548921108246, \tError: 0.09375\n",
      "Loss: 0.19335722923278809, \tError: 0.1875\n",
      "Loss: 0.1208958551287651, \tError: 0.0625\n",
      "Loss: 0.2222897708415985, \tError: 0.1875\n",
      "Loss: 0.05140280723571777, \tError: 0.0\n",
      "Loss: 0.15288138389587402, \tError: 0.09375\n",
      "Loss: 0.11086191236972809, \tError: 0.0625\n",
      "Loss: 0.13053159415721893, \tError: 0.03125\n",
      "Loss: 0.16301824152469635, \tError: 0.125\n",
      "Loss: 0.1675216406583786, \tError: 0.125\n",
      "Loss: 0.17488177120685577, \tError: 0.09375\n",
      "Loss: 0.11080018430948257, \tError: 0.0625\n",
      "Loss: 0.09253431111574173, \tError: 0.03125\n",
      "Loss: 0.07406210899353027, \tError: 0.0\n",
      "Loss: 0.11015442758798599, \tError: 0.09375\n",
      "Loss: 0.09980838745832443, \tError: 0.0625\n",
      "Loss: 0.16979587078094482, \tError: 0.15625\n",
      "Loss: 0.045732349157333374, \tError: 0.03125\n",
      "Loss: 0.021294398233294487, \tError: 0.0\n",
      "Loss: 0.11496129631996155, \tError: 0.03125\n",
      "Loss: 0.2227431833744049, \tError: 0.125\n",
      "Loss: 0.058451905846595764, \tError: 0.0\n",
      "Loss: 0.15450617671012878, \tError: 0.125\n",
      "Loss: 0.0777253732085228, \tError: 0.03125\n",
      "Loss: 0.06850972771644592, \tError: 0.03125\n",
      "Loss: 0.06899811327457428, \tError: 0.0\n",
      "Loss: 0.06994763016700745, \tError: 0.0625\n",
      "Loss: 0.17573973536491394, \tError: 0.09375\n",
      "Loss: 0.1376815140247345, \tError: 0.09375\n",
      "Loss: 0.1540490686893463, \tError: 0.09375\n",
      "Loss: 0.11387710273265839, \tError: 0.09375\n",
      "Loss: 0.09917762875556946, \tError: 0.0625\n",
      "Loss: 0.14847056567668915, \tError: 0.125\n",
      "Loss: 0.03562339395284653, \tError: 0.0\n",
      "Loss: 0.24432086944580078, \tError: 0.0625\n",
      "Loss: 0.11211469024419785, \tError: 0.09375\n",
      "Loss: 0.17121832072734833, \tError: 0.125\n",
      "Loss: 0.09204564988613129, \tError: 0.09375\n",
      "Loss: 0.13399168848991394, \tError: 0.0625\n",
      "Loss: 0.23958414793014526, \tError: 0.15625\n",
      "Loss: 0.053389158099889755, \tError: 0.03125\n",
      "Loss: 0.19250883162021637, \tError: 0.09375\n",
      "Loss: 0.08427751064300537, \tError: 0.03125\n",
      "Loss: 0.08322293311357498, \tError: 0.03125\n",
      "Loss: 0.13373500108718872, \tError: 0.0625\n",
      "Loss: 0.1057596504688263, \tError: 0.0625\n",
      "Loss: 0.11500076949596405, \tError: 0.0625\n",
      "Loss: 0.1951260268688202, \tError: 0.125\n",
      "Loss: 0.11330781877040863, \tError: 0.0625\n",
      "Loss: 0.1504572331905365, \tError: 0.09375\n",
      "Loss: 0.11104648560285568, \tError: 0.0625\n",
      "Loss: 0.14318114519119263, \tError: 0.0625\n",
      "Loss: 0.18040238320827484, \tError: 0.09375\n",
      "Loss: 0.142634779214859, \tError: 0.125\n",
      "Loss: 0.1831924319267273, \tError: 0.125\n",
      "Loss: 0.1263708472251892, \tError: 0.03125\n",
      "Loss: 0.0613529235124588, \tError: 0.03125\n",
      "Loss: 0.07346060127019882, \tError: 0.0\n",
      "Loss: 0.09159988164901733, \tError: 0.0625\n",
      "Loss: 0.17375965416431427, \tError: 0.09375\n",
      "Loss: 0.17413635551929474, \tError: 0.15625\n",
      "Loss: 0.04412802308797836, \tError: 0.03125\n",
      "Loss: 0.018057357519865036, \tError: 0.0\n",
      "Loss: 0.10236643999814987, \tError: 0.03125\n",
      "Loss: 0.14606326818466187, \tError: 0.09375\n",
      "Loss: 0.08697260916233063, \tError: 0.03125\n",
      "Loss: 0.16646049916744232, \tError: 0.125\n",
      "Loss: 0.07565215975046158, \tError: 0.03125\n",
      "Loss: 0.06904517114162445, \tError: 0.03125\n",
      "Loss: 0.06795905530452728, \tError: 0.0\n",
      "Loss: 0.06936675310134888, \tError: 0.0625\n",
      "Loss: 0.1910542994737625, \tError: 0.09375\n",
      "Loss: 0.14864949882030487, \tError: 0.125\n",
      "Loss: 0.15650412440299988, \tError: 0.09375\n",
      "Loss: 0.12251939624547958, \tError: 0.0625\n",
      "Loss: 0.11081194877624512, \tError: 0.09375\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for i in range(number_of_batches):\n",
    "        first_index = i*number_of_samples_per_batch\n",
    "        second_index = (i*number_of_samples_per_batch) + number_of_samples_per_batch\n",
    "        batch = train_gameboards[first_index:second_index]\n",
    "        batchLabels = train_labels[first_index:second_index]\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            Error, Loss = sess.run([error, loss], feed_dict={gameboards:batch, labels:batchLabels, keep_prob:1.0})\n",
    "            print(\"Loss: {}, \\tError: {}\".format(Loss, Error))\n",
    "        sess.run(train, feed_dict={gameboards:batch, labels:batchLabels, keep_prob:1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Error = sess.run(error, feed_dict={gameboards:test_gameboards, labels:test_labels, keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.468715\n"
     ]
    }
   ],
   "source": [
    "print(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
